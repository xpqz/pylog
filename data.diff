diff --git a/docs/STAGE_3_PLAN.md b/docs/STAGE_3_PLAN.md
new file mode 100644
index 0000000..fce77dc
--- /dev/null
+++ b/docs/STAGE_3_PLAN.md
@@ -0,0 +1,708 @@
+# Stage 3: Debug & Observability Implementation Plan
+
+*Comprehensive debugging, tracing, and observability infrastructure for understanding and reproducing Prolog execution behavior.*
+
+---
+
+## Overview
+
+Stage 3 introduces a complete debug and observability layer that allows developers to see the machine at work, understand execution flow, and reproduce failures reliably. The implementation provides both human-readable and machine-parseable outputs while maintaining minimal performance overhead when disabled.
+
+## Goals
+
+1. **Complete visibility** into engine execution via ports tracer
+2. **Reproducible debugging** through deterministic traces and snapshots
+3. **Performance analysis** via metrics and counters
+4. **Low overhead** when tracing is disabled (≤5%)
+5. **Machine-readable output** for tooling and analysis
+6. **Integration points** for CI and debugging workflows
+
+## Trace Invariants
+
+The tracer maintains strict invariants that tests will verify:
+
+1. **step_id** strictly increases by 1 per emitted event
+2. **frame_depth** == len(frame_stack) at all times
+3. **cp_depth** == len(cp_stack) at all times  
+4. **goal_height** == len(goal_stack) at all times
+5. **Port sequences** follow valid transitions:
+   - Successful goal: CALL → EXIT
+   - Failed goal: CALL → FAIL
+   - Non-deterministic: CALL → EXIT → REDO → (EXIT|FAIL) → ...
+6. **Determinism**: With timestamps disabled, identical runs produce byte-for-byte identical traces
+
+## Architecture
+
+### Core Components
+
+#### 1. Ports Tracer System
+```python
+class TraceEvent:
+    """Single trace event with all metadata."""
+    version: int = 1          # Schema version
+    run_id: str               # UUID for this query run
+    step_id: int              # Global monotonic counter
+    port: str                 # 'call'|'exit'|'redo'|'fail'
+    goal: Term                # Current goal being traced
+    goal_pretty: str          # Pretty-printed goal
+    goal_canonical: str       # Canonical form for parsing
+    frame_depth: int          # Frame stack depth (not recursion!)
+    cp_depth: int             # Choicepoint stack depth
+    goal_height: int          # Goal stack height
+    write_stamp: int          # Write stamp from engine
+    pred_id: str              # Interned "name/arity"
+    bindings: Optional[Dict]  # Variable bindings (configurable)
+    monotonic_ns: Optional[int]  # For timing (humans only)
+
+class InternalEvent(TraceEvent):
+    """Extended debug events (optional, off by default)."""
+    kind: str  # 'cp_push'|'cp_pop'|'frame_push'|'frame_pop'|'cut_commit'|'catch_switch'
+    details: Dict  # Event-specific data
+
+class PortsTracer:
+    """Main tracer managing events and output."""
+    def __init__(self, engine: Engine):
+        self.engine = engine
+        self.step_counter = 0
+        self.run_id = str(uuid.uuid4())
+        self.filters = TraceFilters()
+        self.sinks = []
+        self.spypoints = set()  # Set of (name, arity) tuples
+        self.bindings_policy = 'none'  # 'none'|'names'|'names_values'
+        self.max_term_depth = 4
+        self.max_items_per_list = 10
+        self.enable_internal_events = False
+    
+    def emit_event(self, port: str, goal: Term, **metadata):
+        """Emit a trace event through configured sinks."""
+```
+
+#### 2. Snapshot System
+```python
+@dataclass
+class EngineSnapshot:
+    """Complete engine state at a point in time."""
+    run_id: str
+    step_id: int
+    # Heights and tops
+    store_size: int
+    trail_length: int
+    trail_top: int
+    goal_height: int
+    goal_top: int
+    frame_height: int
+    frame_top: int
+    cp_depth: int
+    cp_top: int
+    catch_stack_depth: int
+    write_stamp: int
+    # Detailed structures
+    choicepoints: List[CPSnapshot]
+    frames: List[FrameSnapshot]
+    # Metrics
+    candidates_considered: int  # From indexing
+    memory_bytes: Optional[int]
+
+@dataclass
+class CPSnapshot:
+    """Choicepoint details."""
+    kind: str  # 'choice'|'cut_barrier'|'catch'
+    goal_height: int
+    frame_height: int
+    trail_top: int
+    stamp: int
+    pred_id: str
+
+@dataclass
+class FrameSnapshot:
+    """Frame details."""
+    frame_id: int
+    pred_id: str
+    goal_height_at_entry: int
+
+class SnapshotManager:
+    """Manage snapshots and diffs."""
+    def snapshot(self, engine: Engine) -> EngineSnapshot:
+        """Capture current engine state."""
+    
+    def diff(self, before: EngineSnapshot, after: EngineSnapshot) -> SnapshotDiff:
+        """Compute typed difference between snapshots."""
+
+@dataclass
+class SnapshotDiff:
+    """Structured diff between snapshots."""
+    heights: Dict[str, int]  # Deltas for each height
+    trail: Dict[str, Any]    # Trail changes
+    cp: Dict[str, Any]       # {"delta": +N, "popped": [...]}
+    frames: Dict[str, Any]   # Frame changes
+```
+
+#### 3. Metrics & Counters
+```python
+@dataclass
+class PredMetrics:
+    """Per-predicate metrics."""
+    calls: int = 0
+    exits: int = 0
+    fails: int = 0
+    redos: int = 0
+    unifications: int = 0
+    backtracks: int = 0
+
+class EngineMetrics:
+    """Performance and behavior metrics."""
+    # Global counters
+    unifications_attempted: int = 0
+    unifications_succeeded: int = 0
+    backtracks_taken: int = 0
+    cuts_executed: int = 0
+    alternatives_pruned: int = 0
+    exceptions_thrown: int = 0
+    exceptions_caught: int = 0
+    candidates_considered: int = 0  # From indexing
+    candidates_yielded: int = 0     # From indexing
+    
+    # Per-predicate
+    per_pred: Dict[str, PredMetrics] = field(default_factory=dict)
+    
+    def reset(self):
+        """Reset all counters for new query."""
+        # Clear all fields
+    
+    def to_dict(self) -> Dict[str, Any]:
+        """Export metrics as dictionary."""
+```
+
+#### 4. Output Sinks with Backpressure
+```python
+class TraceSink(ABC):
+    """Abstract base for trace output destinations."""
+    def __init__(self, buffer_size: int = 1000):
+        self.buffer = collections.deque(maxlen=buffer_size)
+        self.events_dropped_total = 0
+        self.events_dropped_recent = 0
+        self.drop_reason = None
+    
+    @abstractmethod
+    def write_event(self, event: TraceEvent):
+        """Write event with backpressure handling."""
+
+class PrettyTraceSink(TraceSink):
+    """Human-readable single-line trace output."""
+    def write_event(self, event: TraceEvent):
+        # Format: [123] call(5): append([1,2], [3], _G123) @ frame=2 cp=1
+        pass
+
+class JSONLTraceSink(TraceSink):
+    """Machine-readable JSONL output."""
+    def write_event(self, event: TraceEvent):
+        # Compact format with schema version
+        obj = {
+            "v": 1,
+            "rid": event.run_id,
+            "sid": event.step_id,
+            "p": self._encode_port(event.port),  # 0=call,1=exit,2=redo,3=fail
+            "pid": event.pred_id,
+            "fd": event.frame_depth,
+            "cd": event.cp_depth,
+            "gh": event.goal_height,
+            "ws": event.write_stamp,
+            "g": event.goal_pretty,
+            "gc": event.goal_canonical
+        }
+        # Optional fields
+        if event.bindings:
+            obj["b"] = event.bindings
+        if event.monotonic_ns:
+            obj["t"] = event.monotonic_ns
+
+class FileTraceSink(TraceSink):
+    """File output with rotation support."""
+    def __init__(self, path: Path, max_size_mb: int = 100, max_files: int = 5):
+        super().__init__()
+        self.path = path
+        self.max_size = max_size_mb * 1024 * 1024
+        self.max_files = max_files
+        self.batch_size = 100
+        self.batch = []
+    
+    def rotate_if_needed(self):
+        """Rotate file.log → file.log.1 → ... → file.log.N"""
+```
+
+#### 5. Filters with Precedence
+```python
+class TraceFilters:
+    """Composable trace filters with defined precedence."""
+    def __init__(self):
+        self.port_filter = None      # Set of allowed ports
+        self.pred_filter = None      # Set of allowed predicates
+        self.depth_range = None      # (min, max) frame depth
+        self.sampling_rate = 1       # 1 = all, N = 1/N events
+        self.sample_counter = 0
+    
+    def should_emit(self, event: TraceEvent) -> bool:
+        """Apply filters in order: port → pred → depth → sampling."""
+        # 1. Port filter
+        if self.port_filter and event.port not in self.port_filter:
+            return False
+        
+        # 2. Predicate/spypoint filter
+        if self.pred_filter and event.pred_id not in self.pred_filter:
+            return False
+        
+        # 3. Depth filter
+        if self.depth_range:
+            min_d, max_d = self.depth_range
+            if not (min_d <= event.frame_depth <= max_d):
+                return False
+        
+        # 4. Sampling
+        if self.sampling_rate > 1:
+            self.sample_counter += 1
+            if self.sample_counter % self.sampling_rate != 0:
+                return False
+        
+        return True
+```
+
+### Integration Points
+
+#### Engine Modifications
+```python
+class Engine:
+    def __init__(self, ..., trace=False, debug=False):
+        # Existing initialization
+        self.tracer = PortsTracer(self) if trace else None
+        self.metrics = EngineMetrics() if debug else None
+        self._global_step_id = 0
+    
+    def _trace_port(self, port: str, goal: Term):
+        """Emit trace event if tracing enabled."""
+        if self.tracer:
+            self._global_step_id += 1
+            self.tracer.emit_event(
+                port=port,
+                goal=goal,
+                step_id=self._global_step_id,
+                frame_depth=len(self.frame_stack),
+                cp_depth=len(self.choicepoints),
+                goal_height=len(self.goal_stack),
+                write_stamp=self.write_stamp,
+                # ... other metadata
+            )
+    
+    def _trace_internal(self, kind: str, **details):
+        """Emit internal debug event if enabled."""
+        if self.tracer and self.tracer.enable_internal_events:
+            self._global_step_id += 1
+            self.tracer.emit_internal_event(kind, **details)
+    
+    def _dispatch_predicate(self, goal):
+        """Modified to include trace ports."""
+        self._trace_port('call', goal.term)
+        
+        # Existing predicate dispatch logic
+        success = self._original_dispatch(goal)
+        
+        if success:
+            self._trace_port('exit', goal.term)
+        else:
+            self._trace_port('fail', goal.term)
+        
+        return success
+    
+    def _push_choicepoint(self, cp):
+        """Modified to trace internal events."""
+        self._trace_internal('cp_push', kind=cp.kind, pred_id=cp.pred_id)
+        # Existing logic
+    
+    def _execute_cut(self):
+        """Modified to trace cut commits."""
+        pruned_count = self._count_prunable_cps()
+        self._trace_internal('cut_commit', pruned=pruned_count)
+        # Existing cut logic
+```
+
+#### REPL Commands
+```python
+class PrologREPL:
+    def __init__(self):
+        # Existing initialization
+        self.trace_enabled = False
+        self.spypoints = set()
+        self.trace_config = {
+            'bindings': 'none',
+            'max_depth': 4,
+            'sampling': 1
+        }
+    
+    def cmd_trace(self, arg: str):
+        """Enable/disable/configure tracing."""
+        parts = arg.split()
+        if parts[0] == 'on':
+            self.engine.tracer = PortsTracer(self.engine)
+            self.trace_enabled = True
+        elif parts[0] == 'off':
+            self.engine.tracer = None
+            self.trace_enabled = False
+        elif parts[0] == 'json':
+            # trace json "out.jsonl"
+            path = parts[1] if len(parts) > 1 else "trace.jsonl"
+            sink = JSONLTraceSink(FileTraceSink(Path(path)))
+            self.engine.tracer.add_sink(sink)
+        elif parts[0] == 'pretty':
+            # trace pretty "out.log"
+            path = parts[1] if len(parts) > 1 else "trace.log"
+            sink = PrettyTraceSink(FileTraceSink(Path(path)))
+            self.engine.tracer.add_sink(sink)
+        elif parts[0] == 'sample':
+            # trace sample 10
+            rate = int(parts[1]) if len(parts) > 1 else 10
+            self.engine.tracer.filters.sampling_rate = rate
+    
+    def cmd_spy(self, predicate: str):
+        """Add spypoint: spy append/3"""
+        name, arity = parse_predicate_spec(predicate)
+        self.spypoints.add((name, arity))
+        if self.engine.tracer:
+            self.engine.tracer.spypoints.add((name, arity))
+    
+    def cmd_spys(self):
+        """List all spypoints."""
+        for name, arity in sorted(self.spypoints):
+            print(f"  {name}/{arity}")
+    
+    def cmd_snapshot(self):
+        """Take engine snapshot."""
+        manager = SnapshotManager()
+        snap = manager.snapshot(self.engine)
+        print(f"Snapshot #{snap.step_id} captured:")
+        print(f"  Store: {snap.store_size} cells")
+        print(f"  Trail: {snap.trail_length} entries")
+        print(f"  Goals: {snap.goal_height} pending")
+        print(f"  Choicepoints: {snap.cp_depth} active")
+```
+
+## JSONL Schema
+
+The JSONL format is compact and versioned for machine parsing:
+
+```json
+{
+  "v": 1,                    // Schema version
+  "rid": "uuid-here",        // Run ID
+  "sid": 123,                // Step ID
+  "p": 0,                    // Port: 0=call, 1=exit, 2=redo, 3=fail
+  "pid": "append/3",         // Predicate ID
+  "fd": 2,                   // Frame depth
+  "cd": 1,                   // CP depth
+  "gh": 5,                   // Goal height
+  "ws": 42,                  // Write stamp
+  "g": "append([1,2],[3],_G1)",     // Pretty goal
+  "gc": "','(append(...),is(...))"  // Canonical form
+}
+```
+
+Optional fields:
+- `"b"`: Bindings object (when enabled)
+- `"t"`: Monotonic nanoseconds (when timestamps enabled)
+- `"k"`: Kind for internal events
+- `"d"`: Details for internal events
+
+Full examples will be documented in `docs/TRACE_FORMAT.md`.
+
+## Implementation Phases
+
+### Phase 1: Core Infrastructure (3.0)
+**Files**: `prolog/debug/tracer.py`, `prolog/debug/events.py`
+- [ ] TraceEvent dataclass with all fields
+- [ ] PortsTracer with basic event emission
+- [ ] Integration points in Engine
+- [ ] Call/Exit/Redo/Fail port detection
+- [ ] Step counter and invariant tracking
+- [ ] Frame depth derivation from stacks
+
+### Phase 2: Metrics & Counters (3.2)
+**Files**: `prolog/debug/metrics.py`
+- [ ] EngineMetrics class
+- [ ] Global counter integration
+- [ ] Per-predicate metrics
+- [ ] Unification tracking
+- [ ] Backtrack counting
+- [ ] Cut and pruning metrics
+- [ ] Exception counting
+- [ ] Indexing statistics integration
+- [ ] Clear reset() semantics
+
+### Phase 3: Snapshots & Diffs (3.1)
+**Files**: `prolog/debug/snapshot.py`
+- [ ] EngineSnapshot with heights and tops
+- [ ] CPSnapshot and FrameSnapshot
+- [ ] Snapshot capture from engine state
+- [ ] Typed diff computation (SnapshotDiff)
+- [ ] JSON serialization of snapshots
+- [ ] Human-readable diff output
+
+### Phase 4: Output Sinks (3.4)
+**Files**: `prolog/debug/sinks.py`
+- [ ] TraceSink with ring buffer
+- [ ] Backpressure handling
+- [ ] Drop counters and policies
+- [ ] PrettyTraceSink for humans
+- [ ] JSONLTraceSink with compact schema
+- [ ] FileTraceSink with rotation
+- [ ] Batch writing (flush every N events or M ms)
+
+### Phase 5: Filters & Spypoints (3.0 continued)
+**Files**: `prolog/debug/filters.py`
+- [ ] TraceFilters with precedence
+- [ ] Port filtering
+- [ ] Predicate/spypoint filtering
+- [ ] Depth range filtering
+- [ ] Sampling (1/N events)
+- [ ] Filter combination tests
+
+### Phase 6: REPL Integration (3.4)
+**Files**: Updates to `prolog/repl.py`
+- [ ] trace on/off/json/pretty commands
+- [ ] spy/unspy/spys commands
+- [ ] snapshot command
+- [ ] metrics command
+- [ ] trace sample N command
+- [ ] Configuration loading
+- [ ] Term depth capping in REPL
+
+### Phase 7: Internal Debug Events (3.0 extended)
+**Files**: Updates to `prolog/debug/events.py`, `prolog/engine/`
+- [ ] InternalEvent class
+- [ ] cp_push/cp_pop events
+- [ ] frame_push/frame_pop events
+- [ ] cut_commit with pruning count
+- [ ] catch_switch events
+- [ ] Optional enable flag
+
+### Phase 8: Tooling & CI (3.5)
+**Files**: `tools/replay_trace.py`, `.github/workflows/`
+- [ ] Trace replay tool (reconstruct last 200 steps)
+- [ ] CI artifact collection
+- [ ] Failure reproduction scripts
+- [ ] Performance regression detection
+
+### Phase 9: Exporters (3.3)
+**Files**: `prolog/debug/exporters.py`
+- [ ] Call graph exporter (static analysis)
+- [ ] Constraint graph exporter (placeholder)
+- [ ] DOT format generation
+- [ ] Graph layout hints
+
+### Phase 10: Documentation & Testing
+**Files**: `docs/TRACE_FORMAT.md`, tests
+- [ ] JSONL schema documentation with examples
+- [ ] Trace format examples
+- [ ] Performance overhead tests
+- [ ] Determinism tests
+- [ ] Invariant verification tests
+- [ ] Integration test suite
+
+## Performance Considerations
+
+### Overhead Targets
+- **Tracing disabled**: ≤5% overhead (null checks only)
+- **Pretty tracing**: ≤20% overhead
+- **JSONL tracing**: ≤30% overhead
+- **Full metrics**: ≤10% overhead
+
+### Optimization Strategies
+1. **Lazy evaluation**: Don't format unless needed
+2. **Buffered output**: Batch writes to sinks
+3. **Interned strings**: Predicate names cached
+4. **Minimal allocations**: Reuse event objects
+5. **Conditional compilation**: Use `__debug__` flag
+
+### Bindings Policy
+- **Default**: No bindings (`bindings_policy='none'`)
+- **Optional projections**:
+  - `'names'`: Variable names only (no values)
+  - `'names_values'`: Include values with caps:
+    - `max_term_depth`: Maximum nesting depth
+    - `max_items_per_list`: Maximum list items shown
+- **Determinism**: Stable variable naming using existing fresh-var map
+
+## Testing Strategy
+
+### Critical Tests
+
+#### 1. Port Sequence Invariants
+- Successful goal: CALL → EXIT
+- Failed goal: CALL → FAIL  
+- Non-deterministic: CALL → EXIT → REDO → (EXIT|FAIL) → ...
+- Verify step_id strictly increases
+
+#### 2. Backtracking Determinism
+- Run same query twice
+- JSONL traces must be byte-for-byte identical (timestamps disabled)
+
+#### 3. Indexing + Trace Sanity
+- With indexing on/off, event stream identical
+- Only metrics differ (candidates_considered/yielded)
+
+#### 4. Cut & Exception Events
+- With internal events on: verify cut_commit and catch_switch
+- With internal events off: pure 4-port stream unchanged
+
+#### 5. Snapshot/Diff No-Growth
+- Over pure backtracking (e.g., member/2)
+- Take snapshots every K steps
+- Assert no monotonic growth in heights/trail
+
+#### 6. Sink Backpressure
+- Fill buffer with slow sink
+- Assert drop counters increase
+- Engine progress unaffected
+
+#### 7. Filter Precedence
+- Combine spy + port + depth + sampling
+- Assert filtered JSONL matches expected subset
+
+#### 8. Metrics Correctness
+- Seeded workload
+- Hand-compute expected counts
+- Verify all counters match
+
+### Unit Tests
+- Event creation and filtering
+- Sink output formats
+- Snapshot/diff accuracy
+- Metrics counting
+- Filter combinations
+- Invariant checks
+
+### Integration Tests
+- End-to-end tracing of queries
+- REPL command testing
+- File rotation behavior
+- Performance overhead measurement
+- Determinism verification
+
+### Performance Tests
+- Overhead with tracing disabled
+- Overhead with various trace levels
+- Large trace file handling
+- Memory usage under load
+- Published in CI logs
+
+## Acceptance Criteria
+
+1. **Performance**
+   - [ ] ≤5% overhead with tracing disabled
+   - [ ] ≤20% overhead with pretty tracing
+   - [ ] ≤30% overhead with JSONL tracing
+   - [ ] Measured and published in CI
+
+2. **Functionality**
+   - [ ] All four ports (call/exit/redo/fail) traced correctly
+   - [ ] Spypoints work as expected
+   - [ ] Filters reduce output appropriately
+   - [ ] Snapshots capture complete state
+   - [ ] Internal events toggleable
+
+3. **Output Quality**
+   - [ ] Pretty format readable by humans
+   - [ ] JSONL format parseable by tools
+   - [ ] No Python object IDs leak
+   - [ ] Deterministic output for same input (timestamps disabled)
+   - [ ] Byte-for-byte equality for identical runs
+
+4. **Integration**
+   - [ ] REPL commands work intuitively
+   - [ ] CI integration captures failures
+   - [ ] Replay tool reconstructs last 200 steps
+
+## Risks and Mitigations
+
+| Risk | Impact | Mitigation |
+|------|--------|------------|
+| High performance overhead | High | Careful profiling, lazy evaluation |
+| Non-deterministic output | Medium | No timestamps by default, stable var naming |
+| Memory leaks from tracing | High | Bounded buffers, rotation, drop policy |
+| Complex integration | Medium | Incremental phases, extensive testing |
+| Breaking existing code | Low | Feature flags, backward compatibility |
+| Sink backpressure | Medium | Ring buffers, drop counters |
+
+## Implementation Order (Low Risk → High Value)
+
+1. **3.0 Minimal tracer**: step_id, 4 ports, pred_id, heights; pretty sink only; off by default
+2. **3.2 Metrics**: global counters, per-predicate; expose in REPL; zero overhead when disabled
+3. **3.1 Snapshots/diffs**: heights + tops + CP/frames data; typed diffs; JSON export
+4. **3.4 JSONL sink**: versioned schema; file sink with buffering & rotation
+5. **Filters & spypoints**: precedence rules; sampling, depth, ports, pred masks
+6. **Replay tool**: consume JSONL; validate step sequence; reconstruct last 200 steps
+7. **Exporters**: call graph from program; constraint graph placeholder
+8. **Internal events**: cp/cut/catch markers (debug-only, off by default)
+
+## Example Usage
+
+### Basic Tracing
+```prolog
+?- trace on.
+Tracing enabled.
+
+?- append([1,2], [3], X).
+[1] call: append([1,2], [3], _G1) @ frame=1 cp=0
+[2] call: append([2], [3], _G2) @ frame=2 cp=0
+[3] call: append([], [3], _G3) @ frame=3 cp=0
+[4] exit: append([], [3], [3]) @ frame=3 cp=0
+[5] exit: append([2], [3], [2,3]) @ frame=2 cp=0
+[6] exit: append([1,2], [3], [1,2,3]) @ frame=1 cp=0
+X = [1,2,3].
+```
+
+### Spypoint
+```prolog
+?- spy append/3.
+Spypoint set on append/3.
+
+?- append(X, Y, [1,2,3]).
+[1] call: append(_G1, _G2, [1,2,3]) @ frame=1
+[2] exit: append([], [1,2,3], [1,2,3]) @ frame=1
+X = [], Y = [1,2,3] ;
+[3] redo: append(_G1, _G2, [1,2,3]) @ frame=1
+[4] exit: append([1], [2,3], [1,2,3]) @ frame=1
+X = [1], Y = [2,3] ;
+...
+```
+
+### Snapshot
+```prolog
+?- snapshot.
+Snapshot #42 captured:
+  Store: 145 cells (top=145)
+  Trail: 89 entries (top=89)
+  Goals: 3 pending (top=3)
+  Frames: 2 active (top=2)
+  Choicepoints: 2 active (top=2)
+  Memory: 14.3 KB
+```
+
+### JSONL Tracing
+```prolog
+?- trace json "debug.jsonl".
+JSONL tracing to debug.jsonl enabled.
+
+?- trace sample 10.
+Sampling 1/10 events.
+```
+
+## Notes
+
+- Stage 3 provides critical infrastructure for debugging and understanding program behavior
+- The tracer design follows standard Prolog 4-port model with optional internal events
+- All output formats are designed to be deterministic and reproducible
+- Performance overhead is carefully managed through lazy evaluation and buffering
+- Integration with existing engine is through well-defined hooks
+- The engine is **iterative**, not recursive - frame_depth tracks frame stack height
+- Determinism guaranteed only with timestamps disabled
+- Bindings are off by default to minimize overhead and output size
+- Filter precedence is clearly defined: port → pred → depth → sampling
+- The implementation enables future stages (especially constraint debugging)
\ No newline at end of file
diff --git a/docs/TODO-3.md b/docs/TODO-3.md
new file mode 100644
index 0000000..a93f491
--- /dev/null
+++ b/docs/TODO-3.md
@@ -0,0 +1,643 @@
+# TODO: Stage 3 (Debug & Observability)
+
+**Key Policy**: step_id increments ONLY when an event is emitted after filters (post-filter). Filtered events never increment step_id.
+
+## Phase 1: Core Infrastructure (3.0) - Minimal Ports Tracer
+
+### 1. Create Debug Module Structure
+- [ ] Create prolog/debug/ directory
+- [ ] Create prolog/debug/__init__.py
+- [ ] Create prolog/debug/tracer.py
+- [ ] Create prolog/debug/events.py
+- [ ] Add module docstrings explaining debug infrastructure
+- [ ] Import necessary dependencies (Terms, Engine types)
+
+### 2. Implement TraceEvent Dataclass
+- [ ] Write test: TraceEvent contains all required fields
+- [ ] Write test: TraceEvent schema version is 1
+- [ ] Write test: TraceEvent run_id is valid UUID string
+- [ ] Write test: Port must be one of 'call'|'exit'|'redo'|'fail'
+- [ ] Write test: step_id is positive integer
+- [ ] Write test: Depths and heights are non-negative integers
+- [ ] Implement TraceEvent dataclass with frozen=True, slots=True
+- [ ] Add validation for port values
+- [ ] Add pretty and canonical goal representations
+- [ ] Verify dataclass immutability
+
+### 3. Implement PortsTracer Class
+- [ ] Write test: PortsTracer initializes with engine reference
+- [ ] Write test: Step counter starts at 0
+- [ ] Write test: Run ID is generated as UUID
+- [ ] Write test: Default bindings_policy is 'none'
+- [ ] Write test: Default max_term_depth is 4
+- [ ] Write test: Default max_items_per_list is 10
+- [ ] Implement PortsTracer.__init__
+- [ ] Implement step counter management (post-filter only)
+- [ ] Implement run_id generation
+- [ ] Add configuration attributes
+- [ ] Add pred_id interning cache (reset per run_id)
+- [ ] Verify initialization
+
+### 4. Engine Integration Hooks
+- [ ] Write test: Engine accepts trace parameter
+- [ ] Write test: Engine creates PortsTracer when trace=True
+- [ ] Write test: Engine.tracer is None when trace=False
+- [ ] Write test: Engine._global_step_id not used (step_id in tracer)
+- [ ] Modify Engine.__init__ to accept trace parameter
+- [ ] Add tracer creation logic
+- [ ] Add _trace_port stub method
+- [ ] Verify integration points
+
+### 5. Port Detection Logic
+- [ ] Write test: CALL port emitted at goal entry
+- [ ] Write test: EXIT port emitted on success
+- [ ] Write test: FAIL port emitted on failure
+- [ ] Write test: REDO port emitted on backtrack retry
+- [ ] Write test: Port sequence follows valid transitions
+- [ ] Implement _trace_port method in Engine
+- [ ] Hook into _dispatch_predicate
+- [ ] Hook into backtracking logic
+- [ ] Verify port emission
+
+### 6. Stack Depth Tracking & Invariants
+- [ ] Write test: frame_depth equals len(frame_stack)
+- [ ] Write test: cp_depth equals len(choicepoints)
+- [ ] Write test: goal_height equals len(goal_stack)
+- [ ] Write test: write_stamp is monotonic
+- [ ] Write test: Depths update correctly during execution
+- [ ] Write test: Depths restored correctly on backtrack
+- [ ] Implement depth extraction in emit_event
+- [ ] Add write_stamp tracking
+- [ ] Create invariant_checker helper (reused in later phases)
+- [ ] Verify invariants hold
+
+### 7. Predicate ID Interning
+- [ ] Write test: Predicate IDs format as "name/arity"
+- [ ] Write test: Same predicate gets same ID
+- [ ] Write test: Different predicates get different IDs
+- [ ] Write test: Built-ins have correct IDs
+- [ ] Write test: Interning cache resets per run_id
+- [ ] Implement pred_id extraction
+- [ ] Add interning cache for efficiency
+- [ ] Verify ID consistency
+
+### 8. Pretty Output Sink (Minimal)
+- [ ] Write test: Pretty format is human-readable single line
+- [ ] Write test: Format includes step_id in brackets
+- [ ] Write test: Format includes port name
+- [ ] Write test: Format includes goal pretty form
+- [ ] Write test: Format includes frame and cp depths
+- [ ] Write test: Long goals are truncated with ellipsis
+- [ ] Write test: Caps apply (max_term_depth=4, max_items_per_list=10)
+- [ ] Implement minimal PrettyTraceSink
+- [ ] Format: "[123] call(5): append([1,2], [3], _G123) @ frame=2 cp=1"
+- [ ] Add term truncation logic
+- [ ] Direct stdout output (no buffering yet)
+- [ ] Verify output format
+
+## Phase 2: Metrics & Counters (3.2)
+
+### 1. Create Metrics Module
+- [ ] Create prolog/debug/metrics.py
+- [ ] Add module docstring
+- [ ] Import necessary types
+- [ ] Set up module structure
+
+### 2. PredMetrics Dataclass
+- [ ] Write test: PredMetrics tracks calls/exits/fails/redos
+- [ ] Write test: PredMetrics tracks unifications/backtracks
+- [ ] Write test: All counters start at 0
+- [ ] Write test: Counters increment correctly
+- [ ] Implement PredMetrics dataclass with frozen=True, slots=True
+- [ ] Add increment methods
+- [ ] Verify counter accuracy
+
+### 3. EngineMetrics Class
+- [ ] Write test: Global counters start at 0
+- [ ] Write test: unifications_attempted increments
+- [ ] Write test: unifications_succeeded increments
+- [ ] Write test: backtracks_taken increments
+- [ ] Write test: cuts_executed increments
+- [ ] Write test: alternatives_pruned increments
+- [ ] Write test: exceptions_thrown/caught increment
+- [ ] Write test: candidates_considered/yielded from indexing
+- [ ] Implement EngineMetrics class
+- [ ] Add per-predicate metrics dict
+- [ ] Add reset() method
+- [ ] Add to_dict() export method
+- [ ] Verify metrics collection
+
+### 4. Engine Integration for Metrics
+- [ ] Write test: Engine accepts debug parameter
+- [ ] Write test: Engine creates EngineMetrics when debug=True
+- [ ] Write test: Metrics updated during unification
+- [ ] Write test: Metrics updated during backtracking
+- [ ] Write test: Metrics updated during cut
+- [ ] Write test: Metrics reset between queries
+- [ ] Write test: Zero overhead when debug=False
+- [ ] Modify Engine.__init__ for debug parameter
+- [ ] Hook metrics into unification
+- [ ] Hook metrics into backtracking
+- [ ] Hook metrics into cut execution
+- [ ] Hook metrics into indexing (if available)
+- [ ] Verify metric updates
+
+## Phase 3: Snapshots & Diffs (3.1)
+
+### 1. Create Snapshot Module
+- [ ] Create prolog/debug/snapshot.py
+- [ ] Add module docstring
+- [ ] Import necessary types
+- [ ] Set up module structure
+
+### 2. Snapshot Dataclasses
+- [ ] Write test: EngineSnapshot contains all heights and tops
+- [ ] Write test: CPSnapshot captures choicepoint state
+- [ ] Write test: FrameSnapshot captures frame state
+- [ ] Write test: Snapshots are immutable
+- [ ] Implement EngineSnapshot dataclass with frozen=True, slots=True
+- [ ] Implement CPSnapshot dataclass with frozen=True, slots=True
+- [ ] Implement FrameSnapshot dataclass with frozen=True, slots=True
+- [ ] Add JSON serialization
+- [ ] Verify dataclass structure
+
+### 3. SnapshotManager Implementation
+- [ ] Write test: snapshot() captures current engine state
+- [ ] Write test: Store size via store.size() not store.cells
+- [ ] Write test: Trail length matches actual trail
+- [ ] Write test: Heights match stack sizes
+- [ ] Write test: Choicepoints captured correctly
+- [ ] Write test: Frames captured correctly
+- [ ] Implement SnapshotManager.snapshot
+- [ ] Extract all engine state (via public APIs only)
+- [ ] Build structured snapshot
+- [ ] Verify state capture
+
+### 4. Diff Computation
+- [ ] Write test: diff() computes height deltas
+- [ ] Write test: diff() identifies CP changes
+- [ ] Write test: diff() identifies frame changes
+- [ ] Write test: diff() produces typed SnapshotDiff
+- [ ] Write test: diff() handles identical snapshots
+- [ ] Implement SnapshotManager.diff
+- [ ] Compute structured differences
+- [ ] Format human-readable output
+- [ ] Format JSON output
+- [ ] Verify diff accuracy
+
+### 5. No-Growth Verification
+- [ ] Write test: Pure backtracking shows no monotonic growth
+- [ ] Write test: Heights stable across backtrack cycles
+- [ ] Write test: member/2 iteration snapshots show no drift
+- [ ] Write test: Trail compaction detected in diffs
+- [ ] Write test: Memory hints included when available
+- [ ] Add memory measurement utilities
+- [ ] Verify no-growth property
+
+## Phase 4: Output Sinks (3.4) - Pretty & JSONL
+
+### 1. Create Sinks Module
+- [ ] Create prolog/debug/sinks.py
+- [ ] Add module docstring
+- [ ] Import JSON utilities
+- [ ] Set up module structure
+
+### 2. TraceSink Abstract Base
+- [ ] Write test: TraceSink is abstract
+- [ ] Write test: TraceSink has write_event method
+- [ ] Write test: TraceSink has ring buffer with maxlen
+- [ ] Write test: TraceSink tracks events_dropped_total
+- [ ] Implement TraceSink ABC
+- [ ] Add ring buffer implementation
+- [ ] Add drop counter logic
+- [ ] Add batch buffer for efficiency
+- [ ] Verify abstract interface
+
+### 3. Enhanced PrettyTraceSink
+- [ ] Write test: Buffered writes reduce I/O calls
+- [ ] Write test: Output can be redirected to file
+- [ ] Write test: Caps always applied (max_term_depth, max_items_per_list)
+- [ ] Enhance PrettyTraceSink with buffering
+- [ ] Add file output option
+- [ ] Add buffer flushing logic
+- [ ] Verify enhanced output
+
+### 4. JSONLTraceSink Implementation
+- [ ] Write test: JSONL outputs one JSON object per line
+- [ ] Write test: Schema version is 1
+- [ ] Write test: Compact keys used (sid, p, fd, etc.)
+- [ ] Write test: Port encoded as integer (0-3)
+- [ ] Write test: Optional fields omitted when None
+- [ ] Write test: Bindings included when enabled
+- [ ] Write test: Timestamps included when enabled
+- [ ] Write test: Caps apply to bindings output
+- [ ] Write test: run_id and query_id included
+- [ ] Implement JSONLTraceSink.write_event
+- [ ] Use compact schema format
+- [ ] Encode ports as integers
+- [ ] Handle optional fields
+- [ ] Verify JSON validity
+
+### 5. FileTraceSink with Rotation
+- [ ] Write test: FileTraceSink writes to specified path
+- [ ] Write test: File rotates at max_size_mb
+- [ ] Write test: Keeps max_files rotated files
+- [ ] Write test: Rotation preserves old files
+- [ ] Write test: Batch writing reduces I/O
+- [ ] Implement FileTraceSink class
+- [ ] Add rotation logic
+- [ ] Add batch buffer (flush every N events or M ms)
+- [ ] Add flush on close
+- [ ] Verify file operations
+
+### 6. Backpressure Handling
+- [ ] Write test: Buffer drops events when full
+- [ ] Write test: Drop counters track lost events
+- [ ] Write test: Drop reason recorded
+- [ ] Write test: Engine continues despite drops
+- [ ] Write test: step_id stays contiguous (only emitted events count)
+- [ ] Write test: Engine results unaffected by drops
+- [ ] Implement backpressure logic
+- [ ] Add drop policies
+- [ ] Add warning on drops
+- [ ] Expose events_dropped_total in metrics
+- [ ] Verify resilience
+
+## Phase 5: Filters & Spypoints (3.0 continued)
+
+### 1. Create Filters Module
+- [ ] Create prolog/debug/filters.py
+- [ ] Add module docstring
+- [ ] Import filter types
+- [ ] Set up module structure
+
+### 2. TraceFilters Implementation
+- [ ] Write test: Port filter allows only specified ports
+- [ ] Write test: Predicate filter allows only specified predicates
+- [ ] Write test: Depth range filters by frame depth
+- [ ] Write test: Sampling reduces event count by factor
+- [ ] Write test: Filter precedence is port→pred→depth→sample
+- [ ] Write test: All filters applied correctly
+- [ ] Write test: Filtered events don't increment step_id
+- [ ] Implement TraceFilters class
+- [ ] Implement should_emit logic
+- [ ] Add filter combination
+- [ ] Verify filter behavior
+
+### 3. Spypoint Management
+- [ ] Write test: Spypoints stored as (name, arity) tuples
+- [ ] Write test: Only spypoint predicates traced when set
+- [ ] Write test: Multiple spypoints can be active
+- [ ] Write test: Spypoints cleared with unspy
+- [ ] Implement spypoint set management
+- [ ] Integrate with predicate filter
+- [ ] Add spy/unspy logic
+- [ ] Verify spypoint filtering
+
+### 4. Filter Integration
+- [ ] Write test: Tracer applies filters before emit
+- [ ] Write test: step_id increments only for emitted events
+- [ ] Write test: Sampling is deterministic with seed
+- [ ] Hook filters into emit_event (before step_id increment)
+- [ ] Optimize filter checking
+- [ ] Verify performance impact
+
+### 5. Variable Bindings Projection
+- [ ] Write test: 'none' policy includes no bindings
+- [ ] Write test: 'names' policy includes variable names only
+- [ ] Write test: 'names_values' includes names and values
+- [ ] Write test: Values respect max_term_depth
+- [ ] Write test: Lists respect max_items_per_list
+- [ ] Write test: Deterministic variable naming
+- [ ] Write test: Same var gets same name in run
+- [ ] Write test: Fresh vars get _G prefix
+- [ ] Implement binding extraction logic
+- [ ] Add policy configuration
+- [ ] Add depth/length capping
+- [ ] Use existing fresh-var map from engine
+- [ ] Verify binding output
+
+## Phase 6: Replay Tool & CI Integration (3.5)
+
+### 1. Create Trace Replay Tool
+- [ ] Create tools/replay_trace.py
+- [ ] Write test: Tool reads JSONL traces
+- [ ] Write test: Reconstructs last N steps (default 200)
+- [ ] Write test: Validates trace consistency
+- [ ] Write test: Detects invariant violations
+- [ ] Write test: Uses invariant_checker from Phase 1
+- [ ] Implement JSONL parser
+- [ ] Implement step reconstruction
+- [ ] Add validation logic
+- [ ] Verify replay accuracy
+
+### 2. CI Integration
+- [ ] Update GitHub workflow
+- [ ] Write test: CI captures traces on failure
+- [ ] Write test: Artifacts include last 10MB traces
+- [ ] Write test: Snapshot included in artifacts
+- [ ] Add trace collection to CI
+- [ ] Configure artifact upload
+- [ ] Test failure scenarios
+- [ ] Verify CI integration
+
+### 3. Debug Scripts
+- [ ] Create debug/analyze_trace.py
+- [ ] Create debug/trace_stats.py
+- [ ] Write test: Scripts parse JSONL correctly
+- [ ] Write test: Statistics computed accurately
+- [ ] Implement analysis tools
+- [ ] Add statistical summaries
+- [ ] Document tool usage
+
+## Phase 7: Exporters (3.3)
+
+### 1. Graph Export Module
+- [ ] Create prolog/debug/exporters.py
+- [ ] Add module docstring
+- [ ] Import DOT utilities
+- [ ] Set up module structure
+
+### 2. Call Graph Exporter
+- [ ] Write test: Call graph includes all predicates
+- [ ] Write test: Edges represent calls
+- [ ] Write test: Static analysis of clauses
+- [ ] Write test: DOT format is valid
+- [ ] Write test: Graphviz can render output
+- [ ] Implement export_call_graph
+- [ ] Parse clause bodies
+- [ ] Build graph structure
+- [ ] Generate DOT output
+- [ ] Verify graph correctness
+
+### 3. Constraint Graph Placeholder
+- [ ] Write test: Constraint graph has placeholder nodes
+- [ ] Write test: Respects variable identity
+- [ ] Write test: DOT format is valid
+- [ ] Write test: Ready for Stage 5 integration
+- [ ] Implement export_constraint_graph
+- [ ] Create placeholder structure
+- [ ] Generate DOT output
+- [ ] Document future integration
+
+## Phase 8: Internal Debug Events (Optional Extension)
+
+### 1. InternalEvent Class
+- [ ] Write test: InternalEvent extends TraceEvent
+- [ ] Write test: Kind field identifies event type
+- [ ] Write test: Details dict contains event data
+- [ ] Write test: Internal events off by default
+- [ ] Write test: Enabling doesn't change 4-port stream
+- [ ] Implement InternalEvent dataclass with frozen=True, slots=True
+- [ ] Add kind validation
+- [ ] Add details structure
+- [ ] Verify event structure
+
+### 2. Choicepoint Events
+- [ ] Write test: cp_push event on choicepoint creation
+- [ ] Write test: cp_pop event on choicepoint removal
+- [ ] Write test: Events include CP kind and pred_id
+- [ ] Write test: Trail_top included in CP events
+- [ ] Hook into push_choicepoint
+- [ ] Hook into pop_choicepoint
+- [ ] Extract CP metadata
+- [ ] Verify CP tracking
+
+### 3. Frame Events
+- [ ] Write test: frame_push on frame creation
+- [ ] Write test: frame_pop on frame removal
+- [ ] Write test: Events include frame_id and pred_id
+- [ ] Hook into frame operations
+- [ ] Extract frame metadata
+- [ ] Verify frame tracking
+
+### 4. Cut and Catch Events
+- [ ] Write test: cut_commit event on cut execution
+- [ ] Write test: Event includes alternatives_pruned count
+- [ ] Write test: catch_switch event on exception catching
+- [ ] Hook into cut execution
+- [ ] Hook into catch mechanism
+- [ ] Extract pruning counts
+- [ ] Verify special events
+
+## Phase 9: REPL Integration
+
+### 1. Trace Commands
+- [ ] Write test: 'trace on' enables tracing
+- [ ] Write test: 'trace off' disables tracing
+- [ ] Write test: 'trace json FILE' enables JSONL output
+- [ ] Write test: 'trace pretty FILE' enables pretty output
+- [ ] Write test: 'trace sample N' sets sampling rate
+- [ ] Update REPL command parser
+- [ ] Implement cmd_trace method
+- [ ] Handle trace configuration
+- [ ] Verify command behavior
+
+### 2. Spy Commands
+- [ ] Write test: 'spy name/arity' adds spypoint
+- [ ] Write test: 'unspy name/arity' removes spypoint
+- [ ] Write test: 'spys' lists all spypoints
+- [ ] Write test: 'untrace' clears all spypoints
+- [ ] Implement cmd_spy method
+- [ ] Implement cmd_unspy method
+- [ ] Implement cmd_spys method
+- [ ] Verify spy management
+
+### 3. Snapshot Commands
+- [ ] Write test: 'snapshot' captures current state
+- [ ] Write test: Snapshot output is readable
+- [ ] Write test: Snapshot includes all key metrics
+- [ ] Implement cmd_snapshot method
+- [ ] Format snapshot output
+- [ ] Verify snapshot display
+
+### 4. Metrics Commands
+- [ ] Write test: 'metrics' displays current metrics
+- [ ] Write test: 'metrics reset' clears counters
+- [ ] Write test: Metrics output is formatted nicely
+- [ ] Implement cmd_metrics method
+- [ ] Format metrics display
+- [ ] Verify metrics output
+
+## Phase 10: Determinism & Performance
+
+### 1. Trace Determinism Tests
+- [ ] Write test: Identical runs produce identical traces
+- [ ] Write test: JSONL byte-for-byte equal with timestamps disabled
+- [ ] Write test: Variable names deterministic
+- [ ] Write test: Step IDs always sequential (post-filter)
+- [ ] Write test: 4-port stream identical with use_indexing=False/True
+- [ ] Disable timestamps for testing
+- [ ] Verify deterministic output
+- [ ] Document determinism guarantees
+
+### 2. Port Sequence Validation
+- [ ] Write test: CALL must precede EXIT/FAIL
+- [ ] Write test: REDO only after EXIT
+- [ ] Write test: No invalid transitions
+- [ ] Write test: Sequence checker detects violations
+- [ ] Implement sequence validator
+- [ ] Add to test suite
+- [ ] Verify sequences
+
+### 3. Performance Testing
+- [ ] Write test: ≤5% overhead with tracing disabled
+- [ ] Write test: ≤20% overhead with pretty tracing
+- [ ] Write test: ≤30% overhead with JSONL tracing
+- [ ] Write test: ≤10% overhead with metrics only
+- [ ] Create benchmark suite
+- [ ] Measure baseline performance
+- [ ] Measure with each feature
+- [ ] Verify overhead targets
+
+### 4. Memory Impact
+- [ ] Write test: Memory bounded with large traces
+- [ ] Write test: Ring buffer prevents unbounded growth
+- [ ] Write test: File rotation prevents disk fill
+- [ ] Write test: Interning cache bounded per run_id
+- [ ] Measure memory usage
+- [ ] Test with long-running queries
+- [ ] Verify memory bounds
+
+## Phase 11: Documentation
+
+### 1. Create TRACE_FORMAT.md Stub
+- [ ] Create docs/TRACE_FORMAT.md
+- [ ] Document schema version 1
+- [ ] Document compact keys (sid, p, fd, cd, gh, ws, pid, g, rid)
+- [ ] Document port encoding (0=call, 1=exit, 2=redo, 3=fail)
+- [ ] Document optional fields (b=bindings, t=timestamp)
+- [ ] Note: "timestamps optional, determinism relies on step ordering"
+- [ ] Add example traces
+- [ ] Document parsing approach
+
+### 2. User Documentation
+- [ ] Update README with Stage 3 features
+- [ ] Document trace commands
+- [ ] Document spy commands
+- [ ] Document snapshot usage
+- [ ] Document metrics collection
+- [ ] Add debugging guide
+- [ ] Create troubleshooting section
+
+### 3. API Documentation
+- [ ] Document PortsTracer API
+- [ ] Document TraceSink interface
+- [ ] Document SnapshotManager API
+- [ ] Document filter system
+- [ ] Document exporter functions
+- [ ] Add docstrings to all public methods
+- [ ] Generate API docs
+
+### 4. Performance Documentation
+- [ ] Document overhead measurements
+- [ ] Document optimization strategies
+- [ ] Document memory usage
+- [ ] Document best practices
+- [ ] Add performance tips
+
+## Phase 12: Integration & Final Testing
+
+### 1. End-to-End Tests
+- [ ] Write test: Complete trace of append/3
+- [ ] Write test: Complete trace of member/2
+- [ ] Write test: Trace with backtracking
+- [ ] Write test: Trace with cut
+- [ ] Write test: Trace with exceptions
+- [ ] Run full scenario tests
+- [ ] Verify trace completeness
+- [ ] Check invariants using invariant_checker
+
+### 2. Compatibility Tests
+- [ ] Run all Stage 1 tests with tracing
+- [ ] Run all Stage 1.5 tests with tracing
+- [ ] Run all Stage 2 tests with tracing
+- [ ] Verify no semantic changes
+- [ ] Verify no test failures
+- [ ] Check performance impact
+
+### 3. Stress Tests
+- [ ] Write test: 1M events without crash
+- [ ] Write test: 100MB trace file handling
+- [ ] Write test: Deep recursion tracing
+- [ ] Write test: Many spypoints active
+- [ ] Run stress scenarios
+- [ ] Verify stability
+
+## Phase 13: Final Validation
+
+### 1. Acceptance Criteria Verification
+- [ ] ✓ ≤5% overhead with tracing disabled
+- [ ] ✓ ≤20% overhead with pretty tracing
+- [ ] ✓ ≤30% overhead with JSONL tracing
+- [ ] ✓ Traces deterministic (timestamps disabled)
+- [ ] ✓ All invariants maintained
+- [ ] ✓ Valid port sequences only
+- [ ] ✓ Snapshot/diff working correctly
+- [ ] ✓ Metrics accurate
+- [ ] ✓ Filters working
+- [ ] ✓ Spypoints working
+- [ ] ✓ REPL integration complete
+- [ ] ✓ File rotation working
+- [ ] ✓ Exporters generating valid DOT
+- [ ] ✓ Replay tool functional
+- [ ] ✓ CI integration complete
+
+### 2. Code Quality
+- [ ] Run black formatter
+- [ ] Remove debug prints
+- [ ] Review TODOs
+- [ ] Check test coverage
+- [ ] Run linter
+- [ ] Fix warnings
+
+### 3. Final Testing
+- [ ] Full test suite passes
+- [ ] Performance tests pass
+- [ ] Integration tests pass
+- [ ] Property tests pass
+- [ ] Manual testing complete
+
+### 4. Stage 3 Completion
+- [ ] Create PR for Stage 3
+- [ ] Ensure CI passes
+- [ ] Code review completed
+- [ ] Merge to main
+- [ ] Update project status
+- [ ] Stage 3 complete
+
+## Implementation Notes
+
+### Key Design Decisions
+- **step_id policy**: Increments ONLY after filters, in emit_event
+- **Dataclass design**: All use frozen=True, slots=True for immutability and memory efficiency
+- **Encapsulation**: Tracer uses only public engine APIs (store.size(), not store.cells)
+- **Interning**: pred_id cache resets per run_id to prevent unbounded growth
+- **Backpressure**: Ring buffer with batch flush, events_dropped_total exposed
+- **Determinism**: Timestamps optional, byte-for-byte reproducibility when disabled
+- **Caps by default**: max_term_depth=4, max_items_per_list=10, bindings_policy='none'
+
+### Performance Targets
+- Tracing disabled: ≤5% overhead (null checks only)
+- Pretty tracing: ≤20% overhead
+- JSONL tracing: ≤30% overhead
+- Metrics only: ≤10% overhead
+
+### Testing Strategy
+- **Invariant checker**: Created once in Phase 1, reused throughout
+- **Indexing parity**: 4-port stream identical with/without indexing
+- **No-growth property**: Snapshots over pure backtracking show no drift
+- **Determinism**: JSONL traces byte-for-byte identical (timestamps off)
+
+### Phase Dependencies
+- Phase 1 creates invariant_checker used by Phases 6, 10, 12
+- Phase 2 metrics exposed in Phase 4 backpressure
+- Phase 3 snapshots used in CI (Phase 6)
+- Filters (Phase 5) must come after sinks (Phase 4)
+- TRACE_FORMAT.md stub (Phase 11) can be created early
+
+### Integration Points
+- Engine hooks: _trace_port, metrics updates
+- REPL commands: trace, spy, snapshot, metrics
+- CI: Artifact collection on failure
+- Tools: replay_trace.py for debugging
\ No newline at end of file
diff --git a/docs/TRACE_FORMAT.md b/docs/TRACE_FORMAT.md
new file mode 100644
index 0000000..721c2f1
--- /dev/null
+++ b/docs/TRACE_FORMAT.md
@@ -0,0 +1,119 @@
+# Trace Format Specification
+
+## Schema Version 1
+
+This document defines the JSONL trace format for PyLog's debug infrastructure.
+
+## Core Design Principles
+
+- **Compact keys** for minimal overhead
+- **Optional fields** omitted when None/empty
+- **Determinism** - timestamps optional, determinism relies on step ordering
+- **Versioned** - schema version in every record
+
+## JSONL Format
+
+Each line is a valid JSON object representing one trace event.
+
+### Required Fields
+
+| Key | Type | Description |
+|-----|------|-------------|
+| `v` | int | Schema version (currently 1) |
+| `rid` | string | Run ID (UUID for this query execution) |
+| `sid` | int | Step ID (monotonic, post-filter only) |
+| `p` | int | Port: 0=call, 1=exit, 2=redo, 3=fail |
+| `pid` | string | Predicate ID ("name/arity") |
+| `fd` | int | Frame depth (frame stack height) |
+| `cd` | int | Choicepoint depth (CP stack height) |
+| `gh` | int | Goal height (goal stack height) |
+| `ws` | int | Write stamp (engine's write counter) |
+| `g` | string | Goal pretty-printed form |
+
+### Optional Fields
+
+| Key | Type | Description |
+|-----|------|-------------|
+| `qid` | int | Query ID (sequence within run) |
+| `gc` | string | Goal canonical form (for parsing) |
+| `b` | object | Variable bindings (when enabled) |
+| `t` | int | Monotonic nanoseconds (when timestamps enabled) |
+
+### Internal Event Fields (Debug Only)
+
+| Key | Type | Description |
+|-----|------|-------------|
+| `k` | string | Kind of internal event |
+| `d` | object | Event-specific details |
+
+## Example Traces
+
+### Basic 4-Port Trace
+```json
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":1,"p":0,"pid":"append/3","fd":1,"cd":0,"gh":3,"ws":42,"g":"append([1,2],[3],_G1)"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":2,"p":0,"pid":"append/3","fd":2,"cd":0,"gh":4,"ws":43,"g":"append([2],[3],_G2)"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":3,"p":0,"pid":"append/3","fd":3,"cd":0,"gh":5,"ws":44,"g":"append([],[3],_G3)"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":4,"p":1,"pid":"append/3","fd":3,"cd":0,"gh":5,"ws":45,"g":"append([],[3],[3])"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":5,"p":1,"pid":"append/3","fd":2,"cd":0,"gh":4,"ws":46,"g":"append([2],[3],[2,3])"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":6,"p":1,"pid":"append/3","fd":1,"cd":0,"gh":3,"ws":47,"g":"append([1,2],[3],[1,2,3])"}
+```
+
+### With Bindings
+```json
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":1,"p":0,"pid":"append/3","fd":1,"cd":0,"gh":3,"ws":42,"g":"append([1,2],[3],X)","b":{"X":"_G1"}}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":6,"p":1,"pid":"append/3","fd":1,"cd":0,"gh":3,"ws":47,"g":"append([1,2],[3],X)","b":{"X":"[1,2,3]"}}
+```
+
+### With Backtracking (REDO)
+```json
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":10,"p":0,"pid":"member/2","fd":1,"cd":1,"gh":2,"ws":50,"g":"member(X,[1,2,3])"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":11,"p":1,"pid":"member/2","fd":1,"cd":1,"gh":2,"ws":51,"g":"member(1,[1,2,3])"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":12,"p":2,"pid":"member/2","fd":1,"cd":1,"gh":2,"ws":52,"g":"member(X,[1,2,3])"}
+{"v":1,"rid":"a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c","sid":13,"p":1,"pid":"member/2","fd":1,"cd":1,"gh":2,"ws":53,"g":"member(2,[1,2,3])"}
+```
+
+## Port Encoding
+
+The port field `p` uses integer encoding for compactness:
+
+- `0` = CALL (entering a goal)
+- `1` = EXIT (goal succeeded)
+- `2` = REDO (backtracking into goal)
+- `3` = FAIL (goal failed)
+
+## Parsing Approach
+
+```python
+import json
+
+def parse_trace(filepath):
+    """Parse JSONL trace file."""
+    events = []
+    with open(filepath, 'r') as f:
+        for line in f:
+            event = json.loads(line)
+            # Decode port
+            port_map = {0: 'call', 1: 'exit', 2: 'redo', 3: 'fail'}
+            event['port'] = port_map[event['p']]
+            events.append(event)
+    return events
+```
+
+## Determinism Guarantees
+
+When timestamps are disabled (`t` field omitted), traces are byte-for-byte deterministic for identical runs. The step_id (`sid`) provides ordering and only increments for events that pass filters.
+
+## Binding Policies
+
+The `b` field appears based on the configured bindings policy:
+
+- `none`: No `b` field
+- `names`: `b` contains variable names only
+- `names_values`: `b` contains names and values (with depth/length caps applied)
+
+## Notes
+
+- All fields use minimal keys to reduce size
+- The format is designed for streaming (one complete JSON object per line)
+- Schema version allows future evolution
+- Internal events (with `k` and `d` fields) are off by default
\ No newline at end of file
diff --git a/prolog/debug/__init__.py b/prolog/debug/__init__.py
index e69de29..bc97719 100644
--- a/prolog/debug/__init__.py
+++ b/prolog/debug/__init__.py
@@ -0,0 +1,15 @@
+"""
+Debug and observability infrastructure for PyLog.
+
+This module provides comprehensive debugging, tracing, and observability
+capabilities for understanding and reproducing Prolog execution behavior.
+"""
+
+from .tracer import TraceEvent, PortsTracer
+from .sinks import PrettyTraceSink
+
+__all__ = [
+    "TraceEvent",
+    "PortsTracer",
+    "PrettyTraceSink",
+]
\ No newline at end of file
diff --git a/prolog/debug/sinks.py b/prolog/debug/sinks.py
new file mode 100644
index 0000000..696add9
--- /dev/null
+++ b/prolog/debug/sinks.py
@@ -0,0 +1,63 @@
+"""
+Output sinks for trace events.
+
+Provides various output formats including human-readable pretty format
+and machine-parseable JSONL format.
+"""
+
+from abc import ABC, abstractmethod
+from typing import Optional
+import sys
+
+from prolog.debug.tracer import TraceEvent
+
+
+class TraceSink(ABC):
+    """Abstract base for trace output destinations."""
+
+    @abstractmethod
+    def write_event(self, event: TraceEvent):
+        """Write an event to this sink."""
+        pass
+
+
+class PrettyTraceSink(TraceSink):
+    """
+    Human-readable single-line trace output.
+
+    Format: [step_id] port(goal_height): goal @ frame=N cp=M
+    """
+
+    def __init__(self, output=None):
+        """
+        Initialize pretty sink.
+
+        Args:
+            output: Output stream (default: sys.stdout)
+        """
+        self.output = output or sys.stdout
+        self.max_goal_length = 50  # Default max goal length
+
+    def format_event(self, event: TraceEvent) -> str:
+        """
+        Format event as human-readable single line.
+
+        Format: [123] call(5): append([1,2], [3], X) @ frame=2 cp=1
+        """
+        # Truncate goal if needed
+        goal_str = event.goal_pretty
+        if len(goal_str) > self.max_goal_length:
+            goal_str = goal_str[:self.max_goal_length - 3] + "..."
+
+        # Format: [step_id] port(goal_height): goal @ frame=N cp=M
+        return (
+            f"[{event.step_id}] "
+            f"{event.port}({event.goal_height}): "
+            f"{goal_str} @ "
+            f"frame={event.frame_depth} cp={event.cp_depth}"
+        )
+
+    def write_event(self, event: TraceEvent):
+        """Write formatted event to output."""
+        line = self.format_event(event)
+        print(line, file=self.output)
\ No newline at end of file
diff --git a/prolog/debug/tracer.py b/prolog/debug/tracer.py
new file mode 100644
index 0000000..942922d
--- /dev/null
+++ b/prolog/debug/tracer.py
@@ -0,0 +1,169 @@
+"""
+Core tracing infrastructure for PyLog debug system.
+
+Provides the 4-port tracer (call/exit/redo/fail) with minimal overhead
+when disabled and deterministic output for reproducibility.
+"""
+
+import uuid
+from dataclasses import dataclass
+from typing import Any, Dict, List, Optional, TYPE_CHECKING
+
+from prolog.ast.terms import Term, Atom, Struct
+
+if TYPE_CHECKING:
+    from prolog.engine.engine import Engine
+
+
+@dataclass(frozen=True, slots=True)
+class TraceEvent:
+    """
+    Single trace event with all metadata.
+
+    Immutable dataclass with slots for memory efficiency.
+    Schema version 1 for JSONL format compatibility.
+    """
+    version: int  # Schema version (currently 1)
+    run_id: str  # UUID for this query run
+    step_id: int  # Global monotonic counter (post-filter)
+    port: str  # 'call'|'exit'|'redo'|'fail'
+    goal: Term  # Current goal being traced
+    goal_pretty: str  # Pretty-printed goal
+    goal_canonical: str  # Canonical form for parsing
+    frame_depth: int  # Frame stack depth
+    cp_depth: int  # Choicepoint stack depth
+    goal_height: int  # Goal stack height
+    write_stamp: int  # Write stamp from engine
+    pred_id: str  # Interned "name/arity"
+    bindings: Optional[Dict[str, Any]] = None  # Variable bindings (optional)
+    monotonic_ns: Optional[int] = None  # For timing (optional)
+
+
+class PortsTracer:
+    """
+    Main tracer managing events and output.
+
+    Key policies:
+    - step_id increments ONLY after filters (post-filter)
+    - pred_id cache resets per run_id
+    - Default caps: max_term_depth=4, max_items_per_list=10
+    - Default bindings_policy='none'
+    """
+
+    def __init__(self, engine: 'Engine'):
+        """Initialize tracer with engine reference."""
+        self.engine = engine
+        self.step_counter = 0
+        self.run_id = str(uuid.uuid4())
+        self.sinks: List[Any] = []  # Output sinks
+        self.spypoints: set = set()  # Set of (name, arity) tuples
+        self.bindings_policy = 'none'  # 'none'|'names'|'names_values'
+        self.max_term_depth = 4
+        self.max_items_per_list = 10
+        self.enable_internal_events = False
+
+        # Predicate ID interning cache (reset per run)
+        self._pred_id_cache: Dict[tuple, str] = {}
+
+        # Filters (will be implemented in Phase 5)
+        self._filters = None
+
+    def _intern_pred_id(self, name: str, arity: int) -> str:
+        """
+        Intern a predicate ID for efficiency.
+
+        Returns "name/arity" format, cached per run.
+        """
+        key = (name, arity)
+        if key not in self._pred_id_cache:
+            self._pred_id_cache[key] = f"{name}/{arity}"
+        return self._pred_id_cache[key]
+
+    def _reset_for_new_run(self):
+        """Reset tracer state for a new query run."""
+        self.step_counter = 0
+        self.run_id = str(uuid.uuid4())
+        self._pred_id_cache.clear()
+
+    def _create_event(self, port: str, goal: Term) -> TraceEvent:
+        """
+        Create a trace event from current engine state.
+
+        Note: step_id is set to 0 here and updated in emit_event
+        after filters pass.
+        """
+        # Extract predicate name and arity from goal
+        if isinstance(goal, Atom):
+            pred_name = goal.name
+            pred_arity = 0
+        elif isinstance(goal, Struct):
+            pred_name = goal.functor
+            pred_arity = len(goal.args)
+        else:
+            # Variable or other term type
+            pred_name = str(goal)
+            pred_arity = 0
+
+        pred_id = self._intern_pred_id(pred_name, pred_arity)
+
+        # Get pretty and canonical forms
+        # For now, use str() - will be enhanced with proper pretty printer
+        goal_pretty = str(goal)
+        goal_canonical = str(goal)
+
+        # Extract stack depths from engine
+        frame_depth = len(self.engine.frame_stack)
+        cp_depth = len(getattr(self.engine, 'choicepoints', []))
+        goal_height = len(getattr(self.engine, 'goal_stack', []))
+        write_stamp = getattr(self.engine, 'write_stamp', 0)
+
+        # Create event with step_id=0 (will be set post-filter)
+        return TraceEvent(
+            version=1,
+            run_id=self.run_id,
+            step_id=0,  # Set in emit_event after filters
+            port=port,
+            goal=goal,
+            goal_pretty=goal_pretty,
+            goal_canonical=goal_canonical,
+            frame_depth=frame_depth,
+            cp_depth=cp_depth,
+            goal_height=goal_height,
+            write_stamp=write_stamp,
+            pred_id=pred_id,
+            bindings=None,  # Will be added based on policy
+            monotonic_ns=None  # Will be added if timestamps enabled
+        )
+
+    def _should_emit(self, event: TraceEvent) -> bool:
+        """
+        Apply filters to determine if event should be emitted.
+
+        For Phase 1, always return True (no filters yet).
+        """
+        # Phase 5 will implement actual filtering
+        return True
+
+    def emit_event(self, port: str, goal: Term):
+        """
+        Emit a trace event through configured sinks.
+
+        Key policy: step_id increments ONLY for emitted events (post-filter).
+        """
+        # Create event
+        event = self._create_event(port, goal)
+
+        # Apply filters
+        if not self._should_emit(event):
+            return  # Filtered out, no step_id increment
+
+        # Increment step counter ONLY for emitted events
+        self.step_counter += 1
+
+        # Update event with actual step_id
+        from dataclasses import replace
+        event = replace(event, step_id=self.step_counter)
+
+        # Send to all sinks
+        for sink in self.sinks:
+            sink.write_event(event)
\ No newline at end of file
diff --git a/prolog/engine/engine.py b/prolog/engine/engine.py
index 496ed39..50dafbc 100644
--- a/prolog/engine/engine.py
+++ b/prolog/engine/engine.py
@@ -51,7 +51,7 @@ def __init__(
             self.program = IndexedProgram.from_program(program) if not isinstance(program, IndexedProgram) else program
         else:
             self.program = program
-        
+
         self.use_indexing = use_indexing
         self.debug = debug
         self.occurs_check = occurs_check
@@ -63,6 +63,9 @@ def __init__(
         self.frame_stack: List[Frame] = []
         self.cp_stack: List[Choicepoint] = []
 
+        # Add choicepoints alias for tracer compatibility
+        self.choicepoints = self.cp_stack
+
         # Query tracking with fast lookups
         self._query_vars: List[Tuple[int, str]] = []  # [(varid, name), ...] for order
         self._qid_by_name: Dict[str, int] = {}  # name -> varid for fast allocation
@@ -79,6 +82,9 @@ def __init__(
         self.max_steps = max_steps  # Step budget for infinite loop detection
         self._steps_taken = 0  # Counter for steps executed
 
+        # Add write_stamp for tracer
+        self.write_stamp = 0
+
         # Builtin registry: maps (name, arity) -> callable
         self._builtins = {}
         self._register_builtins()
@@ -88,7 +94,7 @@ def __init__(
         self._debug_trail_writes = 0
         self._next_frame_id = 0  # Monotonic frame ID counter
         self._cut_barrier = None  # Legacy field for tests
-        
+
         # Exception handling is done via try/except PrologThrow
 
         # Debug ports for tracing
@@ -96,11 +102,18 @@ def __init__(
 
         # Variable renaming for clause isolation
         self._renamer = VarRenamer(self.store)
-        
+
         # Initialize debug counter if debug mode is enabled
         if self.debug:
             self._candidates_considered = 0
 
+        # Initialize tracer if trace=True
+        if trace:
+            from prolog.debug.tracer import PortsTracer
+            self.tracer = PortsTracer(self)
+        else:
+            self.tracer = None
+
     def reset(self):
         """Reset engine state for reuse."""
         self.store = Store()
@@ -126,6 +139,11 @@ def reset(self):
         # Exception handling is done via try/except PrologThrow
         # Don't reset ports - they accumulate across runs
 
+    def _trace_port(self, port: str, goal: Term):
+        """Emit a trace event if tracing is enabled."""
+        if self.tracer:
+            self.tracer.emit_event(port, goal)
+
     def _register_builtins(self):
         """Register all builtin predicates.
 
diff --git a/prolog/tests/unit/test_tracer.py b/prolog/tests/unit/test_tracer.py
new file mode 100644
index 0000000..4e52885
--- /dev/null
+++ b/prolog/tests/unit/test_tracer.py
@@ -0,0 +1,785 @@
+"""
+Tests for Stage 3 Core Infrastructure - Minimal Ports Tracer.
+
+Tests TraceEvent, PortsTracer, and Engine integration for debug infrastructure.
+"""
+
+import uuid
+from dataclasses import FrozenInstanceError, replace
+import pytest
+
+from prolog.ast.terms import Atom, Int, Var, Struct, List
+from prolog.engine.engine import Engine
+from prolog.debug.tracer import TraceEvent, PortsTracer
+from prolog.debug.sinks import PrettyTraceSink
+
+
+class TestTraceEvent:
+    """Tests for TraceEvent dataclass."""
+
+    def test_trace_event_required_fields(self):
+        """TraceEvent contains all required fields."""
+        event = TraceEvent(
+            version=1,
+            run_id="a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c",
+            step_id=1,
+            port="call",
+            goal=Struct("append", (List((Int(1), Int(2))), List((Int(3),)), Var(1, "X"))),
+            goal_pretty="append([1,2], [3], X)",
+            goal_canonical="append([1,2], [3], _G1)",
+            frame_depth=2,
+            cp_depth=1,
+            goal_height=3,
+            write_stamp=42,
+            pred_id="append/3"
+        )
+
+        assert event.version == 1
+        assert event.run_id == "a3f2c8b1-4d5e-6f7a-8b9c-0d1e2f3a4b5c"
+        assert event.step_id == 1
+        assert event.port == "call"
+        assert event.frame_depth == 2
+        assert event.cp_depth == 1
+        assert event.goal_height == 3
+        assert event.write_stamp == 42
+        assert event.pred_id == "append/3"
+        assert event.goal_pretty == "append([1,2], [3], X)"
+
+    def test_trace_event_schema_version(self):
+        """TraceEvent schema version is 1."""
+        event = TraceEvent(
+            version=1,
+            run_id="test-run",
+            step_id=1,
+            port="call",
+            goal=Atom("true"),
+            goal_pretty="true",
+            goal_canonical="true",
+            frame_depth=0,
+            cp_depth=0,
+            goal_height=1,
+            write_stamp=1,
+            pred_id="true/0"
+        )
+        assert event.version == 1
+
+    def test_trace_event_run_id_format(self):
+        """TraceEvent run_id is valid UUID string."""
+        run_id = str(uuid.uuid4())
+        event = TraceEvent(
+            version=1,
+            run_id=run_id,
+            step_id=1,
+            port="call",
+            goal=Atom("true"),
+            goal_pretty="true",
+            goal_canonical="true",
+            frame_depth=0,
+            cp_depth=0,
+            goal_height=1,
+            write_stamp=1,
+            pred_id="true/0"
+        )
+        # Should be valid UUID format
+        uuid.UUID(event.run_id)  # Will raise if invalid
+
+    @pytest.mark.parametrize("port", ["call", "exit", "redo", "fail"])
+    def test_trace_event_port_values(self, port):
+        """Port must be one of 'call'|'exit'|'redo'|'fail'."""
+        event = TraceEvent(
+            version=1,
+            run_id="test",
+            step_id=1,
+            port=port,
+            goal=Atom("true"),
+            goal_pretty="true",
+            goal_canonical="true",
+            frame_depth=0,
+            cp_depth=0,
+            goal_height=1,
+            write_stamp=1,
+            pred_id="true/0"
+        )
+        assert event.port == port
+
+    def test_trace_event_step_id_positive(self):
+        """step_id is positive integer."""
+        event = TraceEvent(
+            version=1,
+            run_id="test",
+            step_id=42,
+            port="call",
+            goal=Atom("true"),
+            goal_pretty="true",
+            goal_canonical="true",
+            frame_depth=0,
+            cp_depth=0,
+            goal_height=1,
+            write_stamp=1,
+            pred_id="true/0"
+        )
+        assert event.step_id == 42
+        assert event.step_id > 0
+
+    def test_trace_event_depths_non_negative(self):
+        """Depths and heights are non-negative integers."""
+        event = TraceEvent(
+            version=1,
+            run_id="test",
+            step_id=1,
+            port="call",
+            goal=Atom("true"),
+            goal_pretty="true",
+            goal_canonical="true",
+            frame_depth=0,
+            cp_depth=0,
+            goal_height=0,
+            write_stamp=0,
+            pred_id="true/0"
+        )
+        assert event.frame_depth >= 0
+        assert event.cp_depth >= 0
+        assert event.goal_height >= 0
+        assert event.write_stamp >= 0
+
+    def test_trace_event_immutable(self):
+        """TraceEvent dataclass is immutable (frozen=True)."""
+        event = TraceEvent(
+            version=1,
+            run_id="test",
+            step_id=1,
+            port="call",
+            goal=Atom("true"),
+            goal_pretty="true",
+            goal_canonical="true",
+            frame_depth=0,
+            cp_depth=0,
+            goal_height=1,
+            write_stamp=1,
+            pred_id="true/0"
+        )
+
+        with pytest.raises(FrozenInstanceError):
+            event.step_id = 2
+
+    def test_trace_event_has_slots(self):
+        """TraceEvent uses slots for memory efficiency."""
+        event = TraceEvent(
+            version=1,
+            run_id="test",
+            step_id=1,
+            port="call",
+            goal=Atom("true"),
+            goal_pretty="true",
+            goal_canonical="true",
+            frame_depth=0,
+            cp_depth=0,
+            goal_height=1,
+            write_stamp=1,
+            pred_id="true/0"
+        )
+
+        # Classes with __slots__ don't have __dict__
+        assert not hasattr(event, '__dict__')
+        # Also check that the class has __slots__
+        assert hasattr(type(event), '__slots__')
+
+
+class TestPortsTracer:
+    """Tests for PortsTracer class."""
+
+    def test_tracer_init_with_engine(self):
+        """PortsTracer initializes with engine reference."""
+        engine = Engine(program=[], trace=False)  # Create without tracer first
+        tracer = PortsTracer(engine)
+
+        assert tracer.engine is engine
+
+    def test_tracer_step_counter_starts_at_zero(self):
+        """Step counter starts at 0."""
+        engine = Engine(program=[], trace=False)
+        tracer = PortsTracer(engine)
+
+        assert tracer.step_counter == 0
+
+    def test_tracer_run_id_generated(self):
+        """Run ID is generated as UUID."""
+        engine = Engine(program=[], trace=False)
+        tracer = PortsTracer(engine)
+
+        # Should be valid UUID
+        uuid.UUID(tracer.run_id)  # Will raise if invalid
+
+    def test_tracer_default_bindings_policy(self):
+        """Default bindings_policy is 'none'."""
+        engine = Engine(program=[], trace=False)
+        tracer = PortsTracer(engine)
+
+        assert tracer.bindings_policy == 'none'
+
+    def test_tracer_default_max_term_depth(self):
+        """Default max_term_depth is 4."""
+        engine = Engine(program=[], trace=False)
+        tracer = PortsTracer(engine)
+
+        assert tracer.max_term_depth == 4
+
+    def test_tracer_default_max_items_per_list(self):
+        """Default max_items_per_list is 10."""
+        engine = Engine(program=[], trace=False)
+        tracer = PortsTracer(engine)
+
+        assert tracer.max_items_per_list == 10
+
+    def test_tracer_step_counter_real_emit(self):
+        """Step counter increments only on real event emission."""
+        engine = Engine(program=[], trace=True)
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Emit two events
+        engine._trace_port("call", Atom("first"))
+        engine._trace_port("exit", Atom("first"))
+
+        # Check step IDs are monotonic
+        assert len(events) == 2
+        assert events[0].step_id == 1
+        assert events[1].step_id == 2
+        assert engine.tracer.step_counter == 2
+
+    def test_tracer_pred_id_interning(self):
+        """Predicate ID interning cache."""
+        engine = Engine(program=[], trace=False)
+        tracer = PortsTracer(engine)
+
+        # Cache should start empty
+        assert len(tracer._pred_id_cache) == 0
+
+        # Intern a predicate ID
+        pred_id = tracer._intern_pred_id("append", 3)
+        assert pred_id == "append/3"
+        assert ("append", 3) in tracer._pred_id_cache
+
+        # Same predicate should return cached value (same string)
+        pred_id2 = tracer._intern_pred_id("append", 3)
+        assert pred_id2 == pred_id  # Equal values
+
+        # Different predicate gets different ID
+        pred_id3 = tracer._intern_pred_id("member", 2)
+        assert pred_id3 == "member/2"
+        assert pred_id3 != pred_id
+
+    def test_tracer_pred_id_cache_reset(self):
+        """Interning cache resets per run_id."""
+        engine = Engine(program=[], trace=False)
+        tracer = PortsTracer(engine)
+
+        # Add some cached IDs
+        pred_id1 = tracer._intern_pred_id("append", 3)
+        tracer._intern_pred_id("member", 2)
+        assert len(tracer._pred_id_cache) == 2
+
+        old_run_id = tracer.run_id
+
+        # Reset for new run
+        tracer._reset_for_new_run()
+        assert len(tracer._pred_id_cache) == 0
+        assert tracer.step_counter == 0
+        assert tracer.run_id != old_run_id
+
+        # After reset, same predicate gets new object (fresh cache)
+        pred_id2 = tracer._intern_pred_id("append", 3)
+        assert pred_id2 == "append/3"  # Same value
+        assert pred_id2 == pred_id1  # Equal strings
+        # Not testing object identity since that's an implementation detail
+
+
+class TestEngineIntegration:
+    """Tests for Engine integration with tracing."""
+
+    def test_engine_accepts_trace_parameter(self):
+        """Engine accepts trace parameter."""
+        engine = Engine(program=[], trace=True)
+        assert engine.tracer is not None
+
+        engine2 = Engine(program=[], trace=False)
+        assert engine2.tracer is None
+
+    def test_engine_creates_tracer_when_true(self):
+        """Engine creates PortsTracer when trace=True."""
+        engine = Engine(program=[], trace=True)
+
+        assert isinstance(engine.tracer, PortsTracer)
+        assert engine.tracer.engine is engine
+
+    def test_engine_tracer_none_when_false(self):
+        """Engine.tracer is None when trace=False."""
+        engine = Engine(program=[], trace=False)
+
+        assert engine.tracer is None
+
+    def test_step_id_managed_by_tracer(self):
+        """Step IDs are managed by tracer, not engine."""
+        engine = Engine(program=[], trace=True)
+
+        # Step ID management is in tracer
+        assert hasattr(engine.tracer, 'step_counter')
+        # Not testing for absence of _global_step_id as that's an implementation detail
+
+
+class TestPortDetection:
+    """Tests for port detection logic."""
+
+    def test_call_port_emitted(self):
+        """CALL port emitted at goal entry."""
+        engine = Engine(program=[], trace=True)
+
+        # Mock a goal entry
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Simulate goal entry
+        engine._trace_port("call", Struct("append", (List(()), List(()), Var(1))))
+
+        assert len(events) == 1
+        assert events[0].port == "call"
+
+    def test_exit_port_emitted(self):
+        """EXIT port emitted on success."""
+        engine = Engine(program=[], trace=True)
+
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Simulate successful goal
+        engine._trace_port("exit", Struct("append", (List(()), List(()), List(()))))
+
+        assert len(events) == 1
+        assert events[0].port == "exit"
+
+    def test_fail_port_emitted(self):
+        """FAIL port emitted on failure."""
+        engine = Engine(program=[], trace=True)
+
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Simulate failed goal
+        engine._trace_port("fail", Struct("append", (Atom("x"), List(()), Var(1))))
+
+        assert len(events) == 1
+        assert events[0].port == "fail"
+
+    def test_redo_port_emitted(self):
+        """REDO port emitted on backtrack retry."""
+        engine = Engine(program=[], trace=True)
+
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Simulate backtrack retry
+        engine._trace_port("redo", Struct("member", (Var(1), List((Int(1), Int(2))))))
+
+        assert len(events) == 1
+        assert events[0].port == "redo"
+
+    def test_port_sequence_valid(self):
+        """Port sequence follows valid transitions."""
+        engine = Engine(program=[], trace=True)
+
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Valid sequence: CALL -> EXIT
+        engine._trace_port("call", Atom("true"))
+        engine._trace_port("exit", Atom("true"))
+
+        assert len(events) == 2
+        assert events[0].port == "call"
+        assert events[1].port == "exit"
+
+        # Valid sequence: CALL -> FAIL
+        events.clear()
+        engine._trace_port("call", Atom("fail"))
+        engine._trace_port("fail", Atom("fail"))
+
+        assert len(events) == 2
+        assert events[0].port == "call"
+        assert events[1].port == "fail"
+
+        # Valid sequence with backtracking: CALL -> EXIT -> REDO -> EXIT
+        events.clear()
+        engine._trace_port("call", Struct("member", (Var(1), List((Int(1), Int(2))))))
+        engine._trace_port("exit", Struct("member", (Int(1), List((Int(1), Int(2))))))
+        engine._trace_port("redo", Struct("member", (Var(1), List((Int(1), Int(2))))))
+        engine._trace_port("exit", Struct("member", (Int(2), List((Int(1), Int(2))))))
+
+        assert len(events) == 4
+        assert [e.port for e in events] == ["call", "exit", "redo", "exit"]
+
+    def test_multi_sink_fanout(self):
+        """Multiple sinks receive identical events."""
+        engine = Engine(program=[], trace=True)
+
+        events1 = []
+        events2 = []
+        engine.tracer.sinks = [MockSink(events1), MockSink(events2)]
+
+        engine._trace_port("call", Atom("test"))
+
+        assert len(events1) == 1
+        assert len(events2) == 1
+        assert events1[0].port == events2[0].port
+        assert events1[0].step_id == events2[0].step_id
+
+
+class TestStackDepthTracking:
+    """Tests for stack depth tracking and invariants."""
+
+    def test_frame_depth_equals_frame_stack(self):
+        """frame_depth equals len(frame_stack)."""
+        engine = Engine(program=[], trace=True)
+
+        # Mock frame stack
+        engine.frame_stack = [None, None, None]  # 3 frames
+
+        event = engine.tracer._create_event("call", Atom("true"))
+        assert event.frame_depth == 3
+
+    def test_cp_depth_equals_choicepoints(self):
+        """cp_depth equals len(choicepoints)."""
+        engine = Engine(program=[], trace=True)
+
+        # Mock choicepoint stack
+        engine.choicepoints = [None, None]  # 2 choicepoints
+
+        event = engine.tracer._create_event("call", Atom("true"))
+        assert event.cp_depth == 2
+
+    def test_goal_height_equals_goal_stack(self):
+        """goal_height equals len(goal_stack)."""
+        engine = Engine(program=[], trace=True)
+
+        # Mock goal stack
+        engine.goal_stack = [None, None, None, None]  # 4 goals
+
+        event = engine.tracer._create_event("call", Atom("true"))
+        assert event.goal_height == 4
+
+    def test_write_stamp_monotonic(self):
+        """write_stamp is monotonic."""
+        engine = Engine(program=[], trace=True)
+
+        # Mock write stamps
+        engine.write_stamp = 42
+        event1 = engine.tracer._create_event("call", Atom("true"))
+        assert event1.write_stamp == 42
+
+        engine.write_stamp = 43
+        event2 = engine.tracer._create_event("exit", Atom("true"))
+        assert event2.write_stamp == 43
+        assert event2.write_stamp > event1.write_stamp
+
+    def test_depths_update_during_execution(self):
+        """Depths update correctly during execution."""
+        engine = Engine(program=[], trace=True)
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Simulate execution with changing stack depths
+        engine.frame_stack = [None]
+        engine.choicepoints = []
+        engine.goal_stack = [None]
+        engine._trace_port("call", Atom("first"))
+
+        engine.frame_stack = [None, None]
+        engine.choicepoints = [None]
+        engine.goal_stack = [None, None]
+        engine._trace_port("call", Atom("second"))
+
+        assert events[0].frame_depth == 1
+        assert events[0].cp_depth == 0
+        assert events[0].goal_height == 1
+
+        assert events[1].frame_depth == 2
+        assert events[1].cp_depth == 1
+        assert events[1].goal_height == 2
+
+    def test_depths_restored_on_backtrack(self):
+        """Depths restored correctly on backtrack."""
+        engine = Engine(program=[], trace=True)
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Before backtrack
+        engine.frame_stack = [None, None]
+        engine.choicepoints = [None]
+        engine.goal_stack = [None, None, None]
+        engine._trace_port("exit", Atom("before"))
+
+        # After backtrack (stacks reduced)
+        engine.frame_stack = [None]
+        engine.choicepoints = []
+        engine.goal_stack = [None]
+        engine._trace_port("redo", Atom("after"))
+
+        assert events[0].frame_depth == 2
+        assert events[0].cp_depth == 1
+        assert events[0].goal_height == 3
+
+        assert events[1].frame_depth == 1
+        assert events[1].cp_depth == 0
+        assert events[1].goal_height == 1
+
+    def test_invariant_checker_helper(self):
+        """Create invariant_checker helper (reused in later phases)."""
+        def check_invariants(engine: Engine, event: TraceEvent) -> bool:
+            """Check that all invariants hold."""
+            # Depths must equal actual stack sizes
+            if event.frame_depth != len(engine.frame_stack):
+                return False
+            if event.cp_depth != len(engine.choicepoints):
+                return False
+            if event.goal_height != len(engine.goal_stack):
+                return False
+
+            # Write stamp must be non-negative
+            if event.write_stamp < 0:
+                return False
+
+            # Step ID must be positive
+            if event.step_id <= 0:
+                return False
+
+            return True
+
+        engine = Engine(program=[], trace=True)
+        engine.frame_stack = [None, None]
+        engine.choicepoints = [None]
+        engine.goal_stack = [None, None, None]
+        engine.write_stamp = 10
+
+        event = engine.tracer._create_event("call", Atom("test"))
+        # Use dataclasses.replace instead of _replace
+        event = replace(event, step_id=1)  # Set step_id for testing
+
+        assert check_invariants(engine, event)
+
+        # Break an invariant
+        event_bad = replace(event, frame_depth=999)
+        assert not check_invariants(engine, event_bad)
+
+
+class TestPredicateInterning:
+    """Tests for predicate ID interning."""
+
+    def test_predicate_id_format(self):
+        """Predicate IDs format as 'name/arity'."""
+        engine = Engine(program=[], trace=True)
+
+        pred_id = engine.tracer._intern_pred_id("append", 3)
+        assert pred_id == "append/3"
+
+        pred_id = engine.tracer._intern_pred_id("true", 0)
+        assert pred_id == "true/0"
+
+    def test_same_predicate_same_id(self):
+        """Same predicate gets same ID."""
+        engine = Engine(program=[], trace=True)
+
+        id1 = engine.tracer._intern_pred_id("member", 2)
+        id2 = engine.tracer._intern_pred_id("member", 2)
+
+        assert id1 == id2
+
+    def test_different_predicates_different_ids(self):
+        """Different predicates get different IDs."""
+        engine = Engine(program=[], trace=True)
+
+        id1 = engine.tracer._intern_pred_id("append", 3)
+        id2 = engine.tracer._intern_pred_id("member", 2)
+        id3 = engine.tracer._intern_pred_id("append", 2)  # Different arity
+
+        assert id1 != id2
+        assert id1 != id3
+        assert id2 != id3
+
+    @pytest.mark.parametrize("name,arity,expected", [
+        ("true", 0, "true/0"),
+        ("fail", 0, "fail/0"),
+        ("!", 0, "!/0"),
+        ("=", 2, "=/2"),
+        ("is", 2, "is/2"),
+    ])
+    def test_builtin_pred_ids(self, name, arity, expected):
+        """Built-ins have correct IDs."""
+        engine = Engine(program=[], trace=True)
+        assert engine.tracer._intern_pred_id(name, arity) == expected
+
+    def test_pred_id_from_goal(self):
+        """Derive pred_id from goal without calling _intern_pred_id directly."""
+        engine = Engine(program=[], trace=True)
+        events = []
+        engine.tracer.sinks = [MockSink(events)]
+
+        # Test various goal types
+        engine._trace_port("call", Atom("true"))
+        engine._trace_port("call", Struct("append", (Var(1), Var(2), Var(3))))
+        engine._trace_port("call", Struct("member", (Atom("x"), List(()))))
+
+        assert events[0].pred_id == "true/0"
+        assert events[1].pred_id == "append/3"
+        assert events[2].pred_id == "member/2"
+
+
+class TestPrettyOutput:
+    """Tests for minimal pretty output sink."""
+
+    def test_pretty_format_readable(self):
+        """Pretty format is human-readable single line."""
+        sink = PrettyTraceSink()
+
+        event = TraceEvent(
+            version=1,
+            run_id="test",
+            step_id=123,
+            port="call",
+            goal=Struct("append", (List((Int(1), Int(2))), List((Int(3),)), Var(1, "X"))),
+            goal_pretty="append([1,2], [3], X)",
+            goal_canonical="append([1,2], [3], _G1)",
+            frame_depth=2,
+            cp_depth=1,
+            goal_height=5,
+            write_stamp=42,
+            pred_id="append/3"
+        )
+
+        output = sink.format_event(event)
+        expected = "[123] call(5): append([1,2], [3], X) @ frame=2 cp=1"
+        assert output == expected
+
+    def test_pretty_includes_step_id(self):
+        """Format includes step_id in brackets."""
+        sink = PrettyTraceSink()
+
+        event = TraceEvent(
+            version=1, run_id="test", step_id=42,
+            port="exit", goal=Atom("true"),
+            goal_pretty="true", goal_canonical="true",
+            frame_depth=0, cp_depth=0, goal_height=1,
+            write_stamp=1, pred_id="true/0"
+        )
+
+        output = sink.format_event(event)
+        assert output.startswith("[42]")
+
+    def test_pretty_includes_port_name(self):
+        """Format includes port name."""
+        sink = PrettyTraceSink()
+
+        for port in ["call", "exit", "redo", "fail"]:
+            event = TraceEvent(
+                version=1, run_id="test", step_id=1,
+                port=port, goal=Atom("test"),
+                goal_pretty="test", goal_canonical="test",
+                frame_depth=0, cp_depth=0, goal_height=1,
+                write_stamp=1, pred_id="test/0"
+            )
+
+            output = sink.format_event(event)
+            assert port in output
+
+    def test_pretty_includes_goal(self):
+        """Format includes goal pretty form."""
+        sink = PrettyTraceSink()
+
+        event = TraceEvent(
+            version=1, run_id="test", step_id=1,
+            port="call",
+            goal=Struct("member", (Var(1, "X"), List((Int(1), Int(2), Int(3))))),
+            goal_pretty="member(X, [1,2,3])",
+            goal_canonical="member(_G1, [1,2,3])",
+            frame_depth=1, cp_depth=0, goal_height=2,
+            write_stamp=1, pred_id="member/2"
+        )
+
+        output = sink.format_event(event)
+        assert "member(X, [1,2,3])" in output
+
+    def test_pretty_includes_depths(self):
+        """Format includes frame and cp depths."""
+        sink = PrettyTraceSink()
+
+        event = TraceEvent(
+            version=1, run_id="test", step_id=1,
+            port="call", goal=Atom("test"),
+            goal_pretty="test", goal_canonical="test",
+            frame_depth=3, cp_depth=2, goal_height=5,
+            write_stamp=1, pred_id="test/0"
+        )
+
+        output = sink.format_event(event)
+        assert "frame=3" in output
+        assert "cp=2" in output
+
+    def test_pretty_truncation_contract(self):
+        """Goal truncation respects max_goal_length."""
+        sink = PrettyTraceSink()
+        sink.max_goal_length = 20  # Set max length
+
+        # Create a very long goal
+        long_list = List(tuple(Int(i) for i in range(100)))
+        event = TraceEvent(
+            version=1, run_id="test", step_id=1,
+            port="call",
+            goal=Struct("process", (long_list,)),
+            goal_pretty="process([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,...])",
+            goal_canonical="process([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,...])",
+            frame_depth=1, cp_depth=0, goal_height=1,
+            write_stamp=1, pred_id="process/1"
+        )
+
+        output = sink.format_event(event)
+        # Extract just the goal part (between : and @)
+        goal_part = output.split(": ")[1].split(" @ ")[0]
+
+        # Goal part should not exceed max_goal_length
+        assert len(goal_part) <= sink.max_goal_length
+        # Should contain ellipsis for truncation
+        if len(event.goal_pretty) > sink.max_goal_length:
+            assert "..." in goal_part
+
+    def test_pretty_caps_applied(self):
+        """Caps apply (max_term_depth=4, max_items_per_list=10)."""
+        sink = PrettyTraceSink()
+
+        # Deep nested structure
+        deep = Struct("f", (Struct("g", (Struct("h", (Struct("i", (Atom("deep"),)),)),)),))
+
+        # Long list
+        long_list = List(tuple(Int(i) for i in range(20)))
+
+        event = TraceEvent(
+            version=1, run_id="test", step_id=1,
+            port="call",
+            goal=Struct("test", (deep, long_list)),
+            goal_pretty="test(f(g(h(...))), [0,1,2,3,4,5,6,7,8,9,...])",
+            goal_canonical="test(f(g(h(i(deep)))), [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])",
+            frame_depth=1, cp_depth=0, goal_height=1,
+            write_stamp=1, pred_id="test/2"
+        )
+
+        output = sink.format_event(event)
+        # Should show truncation
+        assert "..." in output
+
+
+# Mock sink for testing
+class MockSink:
+    """Mock sink that collects events for testing."""
+
+    def __init__(self, events_list):
+        self.events = events_list
+
+    def write_event(self, event):
+        self.events.append(event)
\ No newline at end of file
